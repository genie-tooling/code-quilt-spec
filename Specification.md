CodeQuilt Specification v0.7.1-LLM-Semantic

Version: 0.7.1-semantic-py3.11-std25-v1 (Example Version String)
Date: 2025-04-07 *(Assumed date)*
Status: Draft
Goal: Achieve high token compression for LLM interaction with Python code by combining dense syntactic tokens, an implied standard corpus dictionary, a dynamic dictionary, and LLM-generatable semantic pattern tokens. Aims for efficiency gains noticeable below 25k original tokens.
1. Introduction & Purpose

CodeQuilt v0.7.1-LLM-Semantic is designed for representing source code (primarily Python) in a highly compressed, text-based format suitable for Large Language Models (LLMs). It acts as a robust blueprint, minimizing token exchange during generation, debugging, and modification tasks.

This version integrates several compression strategies:

    Dense Fixed Tokens: Single ASCII characters for core syntax (keywords, operators, structure).

    Implied Corpus Dictionary (C): A standardized dictionary, defined by the spec version string (V:), mapping c<n> references to common Python built-ins, stdlib elements, and literals. This dictionary is not transmitted in the header.

    Dynamic Identifier Dictionary (D): A per-message header field (D:) mapping d<n> references to identifiers not present in the implied Corpus Dictionary.

    Semantic Pattern Tokens: Compact tokens representing common logical patterns (e.g., error handling, checks, common assignments), designed to be recognized and generated by the LLM itself.

    Efficient Literal Handling: Inline short literals, X: header field with Base64 for long/multiline literals (l<n>).

    Comment Removal: Comments are discarded by default for maximum compression.

Human readability is sacrificed for token density.
2. Overall Format

A CodeQuilt string consists of two parts separated by the delimiter |||:

`[Header]|||<Body>`

    Header: Contains metadata (V:, D:, etc.). The Corpus Dictionary is implied by V:. Enclosed in square brackets \[].

    Body: The compressed sequence of tokens representing the code logic and structure.

Formally (EBNF):
`codequilt-string ::= "[" header "]" "|||" body-tokens`
3. Header Specification (\[Header])

Uses key-value pairs separated by semicolons ;. Keys are short, case-sensitive. No unnecessary whitespace.

Formally (EBNF):
`header ::= "[" header-field (";" header-field)* "]"`
3.1. Header Fields (v0.7.1-semantic)

    `V:<version>`: (Required) CodeQuilt specification version string. This string uniquely identifies the spec version AND the specific Implied Corpus Dictionary (C) and Fixed Token Mappings (L:) being used.

        Example: V:0.7.1-semantic-py3.11-std25-v1

    `L:<language>[-version]`: (Implied by V:, Optional Override) The target language. Generally redundant if V: is specific, but can be included for clarity.

        Example: L:python-3.11

    `D:[d<n>=identifier,...]`: (Required if non-corpus identifiers exist) Dynamic Identifier Dictionary. Maps d<n> IDs (sequential, starting d0) to identifiers NOT found in the Implied Corpus Dictionary (C). Omit or use D:[] if all identifiers are corpus-mapped.

        Example: D:[d0=my_custom_var,d1=process_specific_data]

    `I:[path1,path2 as alias,...]`: (Optional) List of modules/libraries imported (informational).

        Example: I:[os,pandas as pd]

    `O:[opt1,opt2=value,...]`: (Optional) Reconstruction options/flags.

        Defined Options:

            cmt=k: (Keep Comments) If present, comments MUST be preserved via Base64 encoding in the X: dictionary, referenced by l<n>. Default: Comments Discarded.

            lth=N: (Literal Threshold) Max character length N for string/bytes literals embedded directly in the body. Default: 80 (Recommendation).

        Example: O:[lth=120]

    `C:<algo>-<hash>`: (Optional) Checksum of the intended final code.

        Example: C:sha256-a1b2c3d4...

    `X:[l<n>=base64(literal),...]]`: (Optional) Extended Literal Dictionary. Maps l<n> IDs (sequential, starting l0) to Base64 encoded literals that are multiline, exceed lth, or are comments (if O:cmt=k).

        Example: X:[l0=U0VMRUNUI...==,l1=IyBMb25nIGNvbW1lbnQ...]

3.2. Implied Corpus Dictionary (C)

    This dictionary (c<n>=name_or_literal) is NOT included in the header string.

    Its content is fixed and defined by the V: version string.

    Both the generator (LLM via prompt) and the reconstructor MUST use the standard Corpus Dictionary corresponding to the specified V:.

    See Section 5 for conceptual definition and examples.

4. Body Specification (<Body>)

A continuous string of tokens. Whitespace between tokens is ignored, except within inline string literals.

Formally (EBNF - Simplified):
`body-tokens ::= (token)*`
`token ::= structure-token | fixed-keyword-operator-token | semantic-token | corpus-ref | dynamic-ref | literal-ref | literal-token | preprocessor-token | escape-hatch-token | decorator-prefix`
4.1. Token Types

    Structure Tokens (structure-token):

        `N`: Newline.

        `>`: Increase indentation level for the next line.

        `<`: Decrease indentation level for the next line.

        `{`, `}`: Brace-based block start/end (language-dependent usage).

    Fixed Keyword/Operator Tokens (fixed-keyword-operator-token):

        Single ASCII characters defined by the language profile (V:/L:). See Section 6.

        Examples (Python): D (def), C (class), R (return), ? (if), : (else/etc.), +, -, =, . ( ) [ ], ,, ;, & (and), | (or), ! (!=), ~ (is), @ (in).

    Semantic Tokens (semantic-token):

        Compact representations of common logical patterns, designed for LLM generation. See Section 7.

        Examples: LOG(...), TRYLOG(...), RETN(...), ATTR(...), DBEXEC(...).

    Corpus Reference (corpus-ref):

        Format: c<n> (e.g., c0, c25).

        Refers to the entry with index n in the Implied Corpus Dictionary.

    Dynamic Reference (dynamic-ref):

        Format: d<n> (e.g., d0, d1).

        Refers to the entry with index n in the Dynamic Dictionary (D:) from the header.

    Literal Reference (literal-ref):

        Format: l<n> (e.g., l0, l1).

        Refers to the Base64-decoded entry with index n in the Extended Literal Dictionary (X:) from the header.

    Literal Tokens (literal-token): Direct embedding of simple values.

        Numbers: 123, 3.14, -10.

        Booleans: t (True), f (False).

        None: n (None).

        Short Strings: \'abc\', \"def\\'s\" (Single-line, below lth, uses host language escapes like \\\\, \\', \\n).

        Short Bytes: b\'xyz\', b\"\\\\x01\" (Single-line, below lth).

    Preprocessor Tokens (preprocessor-token): Language-specific (e.g., C/C++ #ifdef). Defined by L:.

    Escape Hatch (escape-hatch-token): L\'{...}\``. Last resort. Content escapes \\->\\\\, }->\\}`.

    Decorator Prefix (decorator-prefix): @. Language-specific (Python).

Note: Comments are discarded by default (O:cmt=k required to preserve via X:/l<n>). There is no explicit comment token.
5. Standard Corpus Dictionary (C) - Conceptual Definition

    This dictionary is fixed and published for each specific V: version string.

    It's derived from static analysis of a representative corpus (e.g., Python stdlib + top N packages).

    The LLM (via prompt) and Reconstructor must use the correct version.

Example Snippet (Illustrative for V:...-py3.11-std25-v1):

```
Corpus Dictionary (Partial - Not part of transmission)

c0=Exception
c1=AttributeError
c2=IndexError
c3=KeyError
c4=ValueError
c5=TypeError
c6=ImportError
c7=ModuleNotFoundError
c8=FileNotFoundError
c9=NotImplementedError
c10=RuntimeError
c11=OSError
c12=sqlite3
c13=JSONDecodeError
c14=StopIteration
c15=BaseException
c16=LookupError
c17=AssertionError
c18=UnicodeError
c19=UnicodeDecodeError
c20=ConnectionError
c21=TimeoutError
c22=PermissionError
c23=ReferenceError
c24=SyntaxError
c25=IndentationError
c26=SystemError
c27=RecursionError
c28=return
c29=import
c30=except
c31=finally
c32=lambda
c33=assert
c34=global
c35=yield
c36=async
c37=await
c38=class
c39=continue
c40=isinstance
c41=getattr
c42=setattr
c43=hasattr
c44=enumerate
c45=filter
c46=sorted
c47=property
c48=classmethod
c49=staticmethod
c50=__init__
c51=__repr__
c52=__str__
c53=__call__
c54=__getitem__
c55=__setitem__
c56=__delitem__
c57=__contains__
c58=__enter__
c59=__exit__
c60=__iter__
c61=__next__
c62=append
c63=extend
c64=insert
c65=remove
c66=reverse
c67=update
c68=values
c69=items
c70=popitem
c71=setdefault
c72=discard
c73=startswith
c74=endswith
c75=replace
c76=strip
c77=split
c78=join
c79=format
c80=encode
c81=decode
c82=streamlit
c83=session_state
c84=sidebar
c85=button
c86=text_input
c87=text_area
c88=slider
c89=selectbox
c90=toggle
c91=expander
c92=markdown
c93=caption
c94=warning
c95=success
c96=toast
c97=spinner
c98=rerun
c99=chat_message
c100=chat_input
c101=columns
c102=container
c103=set_page_config
c104=logging
c105=logger
c106=getLogger
c107=basicConfig
c108=FileHandler
c109=StreamHandler
c110=setLevel
c111=datetime
c112=timedelta
c113=fromisoformat
c114=strftime
c115=pathlib
c116=resolve
c117=exists
c118=is_file
c119=is_dir
c120=read_text
c121=mkdir
c122=connect
c123=cursor
c124=execute
c125=fetchone
c126=fetchall
c127=commit
c128=rollback
c129=lastrowid
c130=rowcount
c131=contextlib
c132=contextmanager
c133=loads
c134=dumps
c135=google
c136=generativeai
c137=configure
c138=list_models
c139=get_model
c140=GenerativeModel
c141=GenerationConfig
c142=generate_content
c143=start_chat
c144=send_message
c145=count_tokens
c146=safety_settings
c147=candidates
c148=prompt_feedback
c149=block_reason
c150=citation_metadata
c151=citation_sources
c152=grounding_metadata
c153=web_search_results
c154=search_entry_point
c155=rendered_content
c156=GoogleSearchRetrieval
c157=dynamic_retrieval_config
c158=dynamic_threshold
c159=disable_attribution
c160=database
c161=manager
c162=context_manager
c163=actions
c164=requests
c165=response
c166=session
c167=collections
c168=defaultdict
c169=OrderedDict
c170=Counter
c171=deque
c172=namedtuple
c173=argparse
c174=ArgumentParser
c175=add_argument
c176=parse_args
c177=subprocess
c178=communicate
c179=unittest
c180=TestCase
c181=assertEqual
c182=assertTrue
c183=assertFalse
c184=assertRaises
c185=threading
c186=Thread
c187=Condition
c188=Semaphore
c189=multiprocessing
c190=Process
c191=Queue
c192=Pool
c193=shutil
c194=copy
c195=move
c196=rmtree
c197=pickle
c198=struct
c199=socket
c200=asyncio
c201=gather
c202=create_task
c203=run_until_complete
c204=sleep
c205=wait
c206=warnings
c207=warn
c208=simplefilter
c209=traceback
c210=format_exc
c211=print_exc
c212=inspect
c213=getmembers
c214=signature
c215=Parameter
c216=functools
c217=partial
c218=lru_cache
c219=wraps
c220=operator
c221=itemgetter
c222=attrgetter
c223=methodcaller
c224=tempfile
c225=NamedTemporaryFile
c226=TemporaryDirectory
c227=itertools
c228=product
c229=permutations
c230=combinations
c231=chain
c232=message
c233=content
c234=conversation
c235=metadata
c236=timestamp
c237=instruction
c238=parameter
c239=context
c240=history
c241=variable
c242=argument
c243=function
c244=module
c245=package
c246=default
c247=result
c248=status
c249=client
c250=server
c251=request

```
6. Fixed Token Mappings (Python Example - Needs Refinement/Testing)

Implied by V:/L:. This defines the core single-character syntax tokens.

    Structure: N > < ( ) [ ] { } , : . ;

    Operators (Primary): = + - * / % & | ^ ~ < >

    Operators (Mapping Suggestions):

        &: and

        |: or

        N: not (Uppercase N distinct from newline N)

        ~: is

        !: !=

        L: <=

        G: >= (Requires available uppercase G)

        ^: ** (If not used for yield)

    Operators (Keep Multi-Char?): == // << >> += -= *= /= %= **= //= &= |= ^= <<= >>= (Benchmark to see if ==, += etc. are efficient enough as 1-2 tokens vs. assigning more symbols).

    Keywords (Uppercase): D(def), C(class), R(return), ?(if), T(try), X(except), Y(finally), P(pass), M(import), J(from), E(elif), B(break), K(continue), Q(del), A(await), S(async), U(raise), Z(assert), O(nonlocal?) ...

    Keywords (Symbol): @(in), $(lambda), _(with), #(as)

    Literals: t(True), f(False), n(None)

(Final mapping requires empirical LLM tokenizer testing).
7. Semantic Pattern Tokens (Python Examples)

Designed to be recognized and generated by the LLM. Parameters use c<n>, d<n>, l<n> or inline literals. : typically separates parameters, {} encloses body tokens for patterns like TRYLOG.

    LOG(<lvl>:<fmt>[:<args...>])

        Expands to: logger.<lvl>(<fmt>, *<args>)

        <lvl>: i, d, e, w, c.

        Example: LOG(e:'Failed: %s':d5) -> logger.error("Failed: %s", e)

    TRYLOG(<err>[:<var>] {<body>})

        Expands to: try: <body> except <err> as <var>: logger.error(f"...: {<var>}", exc_info=True) (Error message format may vary).

        Example: TRYLOG(c9:d5 { R c42() }) -> try: return super() except Exception as e: logger.error(f"...: {e}", exc_info=True)

    RETN(<var>)

        Expands to: if <var> is None: return None

    RETF(<var>)

        Expands to: if not <var>: return (or return None)

    RAISE(<chk>:<var>:<err>[:<args...>])

        Expands to: if <check_logic(<chk>, <var>)>: raise <err>(*<args>)

        <chk>: N(is None), E(empty/false).

    ATTR(<obj>:<attr>:<val>)

        Expands to: <obj>.<attr> = <val>

        Example: ATTR(c18:'_count':0) -> self._count = 0

    DGET(<tgt>:<dct>:<key>:<def>)

        Expands to: <tgt> = <dct>.get(<key>, <def>)

    DBEXEC(<sql>[:<params>])

        Expands to: Standard try/with conn/execute/except log block for SQL execution without fetching results.

    DBFETCH1(<tgt>:<sql>[:<params>])

        Expands to: Standard try/with conn/execute/fetchone/except log block, assigning result to <tgt>.

    CHKEXIT(<msg>:<exit_code>)

        Expands to: Standard orchestrator pattern audit(...); final_response = report_X(...); raise SystemExit(...).

    CHKINIT(<var>:<Class> {<args...>})

        Expands to: global <var>; if <var> is None: <var> = <Class>(*<args>).

    PATHJOIN(<tgt>:<part1>[:<parts...>])

        Expands to: <tgt> = os.path.join(<part1>, *<parts>).

    MKDIRS(<path>)

        Expands to: os.makedirs(<path>, exist_ok=True).

(This list can be extended based on further corpus analysis).
8. Examples

Example 1: Simple Function

```python
Original Python (~15 tokens)

def check_value(x):
if x is None:
return False
return x > 10
```

```codequilt
CodeQuilt v0.7.1 (Conceptual - assumes c17=None, c16=False, D:[d0=check_value, d1=x])

[V:0.7.1...;D:[d0=check_value,d1=x]]|||D d0(d1):N>RETN(d1:c16)N R d1>10N<
Token Count: Header ~7-10 + Body(D d0(d1):N> RETN(d1:c16) N R d1>10 N<) ~15 = ~22-25 tokens
Note: RETN saved tokens vs standard if/return. Still higher than original due to header/dynamics.

```

Example 2: Logging and Attribute Setting

```python
Original Python (~25 tokens)

class Counter:
def init(self):
self.count = 0
logger.info("Counter initialized")

      
def increment(self):
    self.count += 1
    logger.debug(f"Incremented to {self.count}")
```

```codequilt
CodeQuilt v0.7.1 (Conceptual - assumes c18=self, c44=logger, c45=info, c46=debug, D:[d0=Counter, d1=count, d2=increment])

[V:0.7.1...;D:[d0=Counter,d1=count,d2=increment]]|||
C d0: N>
D c_init(c18):N> # Assume c_init = init in Corpus Dict C
ATTR(c18:'count':0) N
LOG(i:'Counter initialized') N<
D d2(c18):N>
c18.d1 += 1 N # Assuming += kept as multi-token
LOG(d:f"Incremented to {c18.d1}") N< # Using f-string in LOG
N<
Token Count: Header ~9-12 + Body ~30 = ~40-45 tokens
Note: ATTR and LOG likely provide savings here compared to raw Python tokens.

```
9. Reconstruction Notes

    Requires: The specific Implied Corpus Dictionary (C) and Fixed Token Mappings associated with the V: string.

    Process:

        Parse Header: Extract V:, D:, I:, O:, C:, X:.

        Build dynamic lookup from D:. Decode Base64 values from X:.

        Load the correct standard Corpus Dictionary C based on V:.

        Tokenize Body: Recognize fixed tokens, semantic tokens, c<n>, d<n>, l<n>, and inline literals.

        Reconstruct Code:

            Substitute c<n> from Corpus Dictionary.

            Substitute d<n> from Dynamic Dictionary.

            Substitute l<n> from decoded X: dictionary.

            Translate fixed tokens to syntax.

            Expand Semantic Tokens: Replace each semantic token (LOG, ATTR, RETN, etc.) with its corresponding Python code block, substituting parameters correctly.

            Handle structure tokens (N, >, <) to format indentation and newlines.

            Apply spacing heuristics (e.g., around operators).

        Post-process (e.g., black formatter), verify checksum (C:).

10. Considerations for LLM Generation

    Prompting is Key: The LLM prompt MUST include:

        The full CodeQuilt specification.

        The entire content of the specific Corpus Dictionary (C) implied by the target V: string.

        Clear definitions and syntax for all Semantic Tokens.

        Instructions to map unknown identifiers to D: / d<n>.

        Instructions to use X: / l<n> for long/multiline literals.

        Explicit instruction to prioritize using Semantic Tokens whenever applicable to maximize compression.

    LLM Pattern Matching: Relies on the LLM's ability to recognize the Python patterns corresponding to the defined semantic tokens.

    Fidelity: Semantic tokens might reconstruct functionally equivalent but not character-for-character identical code (e.g., exact whitespace within the pattern, slightly different logging format string). This is usually acceptable for the goal of compressed representation for further LLM processing.